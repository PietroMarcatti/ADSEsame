{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('../datasets/base_edges.csv')\n",
    "\n",
    "# Add a new column for the increasing ID at the left\n",
    "df.insert(4, 'id', range(1, len(df) + 1))\n",
    "\n",
    "# Save the updated dataframe back to a CSV\n",
    "df.to_csv('../datasets/base_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to process the CSV file\n",
    "def process_csv(input_file, output_file):\n",
    "    # Open the input CSV file\n",
    "    with open(input_file, mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        # Prepare to write to the output CSV file\n",
    "        with open(output_file, mode='w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "\n",
    "            # Iterate over each row in the input CSV\n",
    "            for row in reader:\n",
    "                # Modify the first column by extracting the number part (remove \"W\")\n",
    "                if row:\n",
    "                    if row[0][0] == 'f': continue\n",
    "                    newRow = []\n",
    "                    for item in row:\n",
    "                        if item[0] == 'B':\n",
    "                            number = item[1:]\n",
    "                            newRow.append(str(int(number)+200))\n",
    "                        elif item[0] == 'W':\n",
    "                            number = item[1:]\n",
    "                            newRow.append(str(int(number)))\n",
    "                        elif item[0] == 'w':\n",
    "                            newRow.append(str(0))\n",
    "                        elif item[0] == 'b':\n",
    "                            newRow.append(str(1))\n",
    "                        else:\n",
    "                            newRow.append(str(item))\n",
    "                    \n",
    "                    writer.writerow(newRow)\n",
    "\n",
    "# Example usage\n",
    "input_csv = '../datasets/nodes.csv'  # Replace with the path to your input file\n",
    "output_csv = '../datasets/temp_nodes.csv'  # The path to save the output file\n",
    "\n",
    "process_csv(input_csv, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('nodes.csv')\n",
    "\n",
    "# Add a new column for the increasing ID at the left\n",
    "df.insert(5, 'id', range(1, len(df) + 1))\n",
    "\n",
    "# Save the updated dataframe back to a CSV\n",
    "df.to_csv('nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Repos\\ADS_Esame\\notebooks\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame for the derived edges\u001b[39;00m\n\u001b[0;32m     24\u001b[0m new_edges_0_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(new_edges, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 25\u001b[0m id_counter \u001b[38;5;241m=\u001b[39m \u001b[43mnew_edges_0_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m df_type_1 \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Build adjacency list for the graph using type 0 edges\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Repos\\ADS_Esame\\notebooks\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Repos\\ADS_Esame\\notebooks\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/base_edges.csv\")\n",
    "\n",
    "# Filter for edges of type 0\n",
    "df_type_0 = df[df['type'] == 0]\n",
    "\n",
    "# Build adjacency list for the graph using type 0 edges\n",
    "graph = defaultdict(list)\n",
    "for _, row in df_type_0.iterrows():\n",
    "    graph[row['from']].append(row['to'])\n",
    "    graph[row['to']].append(row['from'])  # Since the graph is undirected\n",
    "\n",
    "# Find all two-step connections (including multiple intermediate paths)\n",
    "new_edges = []\n",
    "id_counter = df['id'].max() + 1  # Start new IDs after the existing ones\n",
    "\n",
    "for intermediate_node in graph:\n",
    "    for node_a in graph[intermediate_node]:\n",
    "        for node_b in graph[intermediate_node]:\n",
    "            if node_a != node_b:  # Allow multiple paths through different intermediates\n",
    "                if []\n",
    "                new_edges.append([id_counter, node_a, node_b, 4, intermediate_node])\n",
    "                id_counter += 1\n",
    "\n",
    "# Create a new DataFrame for the derived edges\n",
    "new_edges_0_df = pd.DataFrame(new_edges, columns=['from', 'to', 'type', 'step', 'id'])\n",
    "id_counter = new_edges_0_df['id'].max()+1\n",
    "df_type_1 = df[df['type'] == 1]\n",
    "\n",
    "# Build adjacency list for the graph using type 0 edges\n",
    "graph = defaultdict(list)\n",
    "for _, row in df_type_1.iterrows():\n",
    "    graph[row['from']].append(row['to'])\n",
    "    graph[row['to']].append(row['from'])  # Since the graph is undirected\n",
    "\n",
    "# Find all two-step connections (including multiple intermediate paths)\n",
    "new_edges = [] \n",
    "\n",
    "for intermediate_node in graph:\n",
    "    for node_a in graph[intermediate_node]:\n",
    "        for node_b in graph[intermediate_node]:\n",
    "            if node_a != node_b:  # Allow multiple paths through different intermediates\n",
    "                new_edges.append([id_counter, node_a, node_b, 5, intermediate_node])\n",
    "                id_counter += 1\n",
    "\n",
    "# Create a new DataFrame for the derived edges\n",
    "new_edges_1_df = pd.DataFrame(new_edges, columns=['from', 'to', 'type', 'step', 'id'])\n",
    "\n",
    "output_file_path = \"../datasets/temp_all_edges.csv\"\n",
    "# Append the new edges to the original DataFrame\n",
    "result_df = pd.concat([df, new_edges_0_df], ignore_index=True)\n",
    "result_df = pd.concat([result_df, new_edges_1_df], ignore_index=True)\n",
    "result_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"New edges added and saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/all_edges.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
